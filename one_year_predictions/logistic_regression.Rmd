---
title: "One-Year Predictions: Logistic Regression"
output: html_document
date: "2024-05-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

Import packages:
```{r}
library(tidyverse)
library(caret)
library(mlbench)
library(glmnet)
library(reshape2)
library(here)
source(here("utils.R"))
set.seed(42)
```

Load data:
```{r}
suppressMessages({
  df <- read_csv(here("data", "agg_one_year.csv"))
})
```

The dependent variable for this analysis is `vol_attrition_next_year`. This is a binary indicator for whether the employee quit in the following year. In the dataset, there are about 19,000 cases where this value is `NA`. These values represent three separate cases: (1) the year of the record was in 2023, so we do not have data for the following year; (2) the employee terminated in that year, so they could not have quit in the following year; or (3) the employee retired in the following year, and we have removed retirements from analysis.

Something else I am filtering out is cases when vol_attrition_next_year == 1 and attrition == 1. This would indicate that the employee is quitting in this year and next year, so they must have been rehired between quits. There are 181 cases of this.

## Full Model

### Data cleaning

I am removing the following variables from the model:
- Cost center (too granular)
- ELT (not informative)
- Continent (redundant because I am including country)
- Number of direct reports (mistrusted feature)
- Company (too granular)
- Management level (correlated with grade grouping)
- Potential (too many NA values)
- Annual review rating (too many NA values)
- Zone (highly correlated with position in range)
- Age (correlated with tenure, created a new variable age / tenure)
- Time in job profile (correlated with tenure, created a new variable tijp / tenure)

```{r}
# Prepare data and input which features to not use:
data <- prepare_data_for_regression(
  df,
  exclude_cols = c("cost_centre",
                   "elt",
                   "continent",
                   "number_of_direct_reports_norm",
                   "company",
                   "management_level_encoded_norm",
                   "potential_encoded_norm",
                   "annual_review_encoded_norm",
                   "zone_encoded_norm",
                   "age_norm",
                   "time_in_job_profile_norm",
                   "tenure_norm",
                   "age_over_tenure_norm",
                   "reporting_hierarchy_level_norm",
                   "rhl_squared_norm",
                   "grade_grouping_encoded_norm")
)
```

Prepare data for model training:
```{r}
set.seed(42)
split <- split_data(data)
train_data <- split[[1]]
validate_data <- split[[2]]
test_data <- split[[3]]
# Combine train data and validate data together (no need for 3 groups):
train_data <- rbind(train_data, validate_data)
```

Get column names of numeric and categorical features:
```{r}
# Get numeric column names:
num_features <- colnames(data)[sapply(data, is.numeric)]
# Remove vol_attrition_next_year:
num_features <- num_features[-length(num_features)]
# Get categorical column names:
cat_features <- names(data)[sapply(data, is.factor)]
```

### Model Training

Train cross-validated lasso regression (skip if already trained):
```{r}
# Separate X and y:
X_y_split <- get_X_y(train_data, cat_features, num_features)
X_train <- X_y_split[[1]]
y_train <- X_y_split[[2]]
# Define class weights to handle imbalanced labels
# - Optional to use
# - If using, add the argument `weights = class_weights`
class_weights <- ifelse(y_train == 0, 1, sum(y_train == 0) / sum(y_train == 1))

# Train model (takes 2-4 minutes):
cv_fit <- cv.glmnet(as.matrix(X_train),
                    y_train,
                    family = "binomial",
                    type.measure = "class")

# Save model:
saveRDS(cv_fit, here("one_year_predictions",
                     "models",
                     "regressions",
                     "cv_model_v6.rds"))
```

Load the model if it has already been trained:
```{r}
cv_fit <- readRDS(here("one_year_predictions",
                       "models",
                       "regressions",
                       "cv_model_v6.rds"))
plot(cv_fit)
```

```{r}
print(cv_fit$lambda.min)
print(cv_fit$lambda.1se)
```

### Model Evaluation

```{r}
lambda = 0.005
X_y <- get_X_y(test_data, cat_features, num_features)
X_test <- X_y[[1]]
y_test <- as.numeric(as.vector(X_y[[2]]))
y_probs <- predict(cv_fit,
                   s = lambda,
                   newx = as.matrix(X_test),
                   type = "response")
file_path <- here("data_visualization", "plots", "lasso_v6_roc.pdf")
evaluate_class_model(y_probs, y_test, threshold = 0.05, file_path)
```

### Most Significant Predictors

```{r}
# Choose complexity penalty:
lambda = 0.005
coefs <- coef(cv_fit, s = lambda)
# Arrange coefficients by descending size:
as.data.frame(as.matrix(coefs)) %>% arrange(desc(abs(s1)))
```

### Make evaluations table:

```{r}
lambda = 0.005
X_y <- get_X_y(data, cat_features, num_features)
X <- X_y[[1]]
y <- as.numeric(as.vector(X_y[[2]]))
y_probs <- predict(cv_fit,
                   s = lambda,
                   newx = as.matrix(X),
                   type = "response")
```

```{r}
mutate(data,
       preds = y_probs[, 1],
       rank = rank(preds, ties.method = "first"),
       percentile = (rank - 1) / nrow(data) * 100,
       percentile_bin = cut(percentile, c(0, 10, 20, 30, 40, 50,
                                          60, 70, 80, 90, 100))) %>%
  group_by(percentile_bin) %>%
  summarize(year_end_count = n(),
            num_exits = sum(vol_attrition_next_year),
            percent_attrition = sum(vol_attrition_next_year) / year_end_count) %>%
  arrange(desc(percentile_bin))
```

### Make predictions on 2023 file:

```{r}
lambda = 0.005
cv_fit <- readRDS(here("one_year_predictions",
                       "models",
                       "regressions",
                       "cv_model_v6.rds"))

# Assign a value of 1 to voluntary attrition to avoid errors in data processing:
df_2023 <- mutate(df, vol_attrition_next_year = 1)

# Prepare all data before filtering because some variables are calculated based
# on other years:
# (ignore no non-missing arguments warning)
data_2023 <- prepare_data_for_regression(
  df_2023,
  exclude_cols = c("cost_centre",
                   "elt",
                   "continent",
                   "number_of_direct_reports_norm",
                   "company",
                   "management_level_encoded_norm",
                   "potential_encoded_norm",
                   "annual_review_encoded_norm",
                   "zone_encoded_norm",
                   "age_norm",
                   "time_in_job_profile_norm",
                   "tenure_norm",
                   "age_over_tenure_norm",
                   "reporting_hierarchy_level_norm",
                   "rhl_squared_norm",
                   "grade_grouping_encoded_norm"),
  prediction_year = 2023
)

# Get numeric column names:
num_features <- colnames(data_2023)[sapply(data_2023, is.numeric)]
# Remove vol_attrition_next_year:
num_features <- num_features[-length(num_features)]
# Get categorical column names:
cat_features <- names(data_2023)[sapply(data_2023, is.factor)]

X_y_split <- get_X_y(data_2023, cat_features, num_features)
X_2023 <- X_y_split[[1]]

y_probs <- predict(cv_fit,
                   s = lambda,
                   newx = as.matrix(X_2023),
                   type = "response")[, 1]

predictions_2023 <- prepare_data(df_2023, prediction_year = 2023)
predictions_2023$prediction <- y_probs

remove_cols <- c("attrition", "vol_attrition", "vol_attrition_next_year",
                 "year", "curr_annual_review", "prev_year_supervisor",
                 "supervisor_change", "prev_job_family", "job_fam_change",
                 "tenure_supervisor", "management_level_encoded",
                 "zone_encoded", "grade_grouping_encoded",
                 "annual_review_encoded", "potential_encoded", "continent")
predictions_2023 <-
  predictions_2023[, !colnames(predictions_2023) %in% remove_cols]
write.csv(predictions_2023, here("one_year_predictions", "models",
                                 "regressions", "lasso_v6_predictions.csv"))
```

