---
title: "R Notebook"
output: html_notebook
date: "2024-05-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

Load packages:
```{r}
library(tidyverse)
library(caret)
library(glmnet)
library(survival)
library(survminer)
library(here)
source(here("utils.R"))
set.seed(42)
```

Load data:
```{r}
df <- read_csv(here("data", "agg_survival.csv"))
```

Prepare data for analysis:
```{r}
data <- prepare_data_for_regression(
  df,
  exclude_cols = c("cost_centre",
                   "elt",
                   "continent",
                   "number_of_direct_reports_norm",
                   "company",
                   "management_level_encoded_norm",
                   "potential_encoded_norm",
                   "annual_review_encoded_norm",
                   "zone_encoded_norm",
                   "age_norm",
                   "time_in_job_profile_norm",
                   "tenure_norm",
                   "age_over_tenure_norm",
                   "reporting_hierarchy_level_norm",
                   "rhl_squared_norm",
                   "grade_grouping_encoded_norm"),
  cox = TRUE
)
```

Prepare data for model training:
```{r}
set.seed(42)
split <- split_data(data)
train_data <- split[[1]]
validate_data <- split[[2]]
test_data <- split[[3]]
# Combine train data and validate data together (no need for 3 groups):
train_data <- rbind(train_data, validate_data)
```

Get column names of numeric and categorical features:
```{r}
# Get numeric column names:
num_features <- colnames(data)[sapply(data, is.numeric)]
# Remove vol_attrition_next_year:
num_features <- num_features[-length(num_features)]
# Get categorical column names:
cat_features <- names(data)[sapply(data, is.factor)]
```

```{r}
# Encode categorical features and get X and y:
X_y_split <- get_X_y(train_data, cat_features, num_features, cox = TRUE)
X_train <- X_y_split[[1]]
y_train <- X_y_split[[2]]
y_train_surv <- Surv(as.numeric(y_train$time),
                     as.numeric(y_train$status))
```

Train cross-validated model to get optimal value of $\lambda$ (takes a few minutes):
```{r}
cv_fit <- cv.glmnet(as.matrix(X_train),
                    y_train_surv,
                    family = "cox",
                    type.measure = "C")
# Save model:
saveRDS(cv_fit, here("survival_analysis", "cv_cox_model_v1.rds"))
# Load model if already trained:
cv_fit <- readRDS(here("survival_analysis", "cv_cox_model_v1.rds"))
plot(cv_fit)
```

Get best $\lambda$ values:
```{r}
print(cv_fit$lambda.min)
print(cv_fit$lambda.1se)
```

```{r}
lambda <- cv_fit$lambda.1se
coefs <- coef(cv_fit, s = lambda)
as.data.frame(as.matrix(coefs)) %>% arrange(desc(abs(`1`)))
```

Evaluate performance on validate set:
```{r}
# Split validation data into X and y:
X_y_split <- get_X_y(test_data, cat_features, num_features, cox = TRUE)
X_test <- X_y_split[[1]]
y_test <- X_y_split[[2]]
y_test_surv <- Surv(as.numeric(y_test$time),
                        as.numeric(y_test$status))
assess.glmnet(cv_fit,
              newx = as.matrix(X_test),
              newy = y_test_surv,
              family = "cox")
```
